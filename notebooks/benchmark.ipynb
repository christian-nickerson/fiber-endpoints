{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM Fiber vs FastAPI inference benchmarking test\n",
    "\n",
    "A benchmarking test to assess the difference in latency for inferencing a LightGBM model endpoint, written in Python's FastAPI vs GoLang's Fiber.\n",
    "\n",
    "Both endpoints are using the same LightGBM model file (trained on synthetic data generated via Sci-kit learn). FastAPI (built on Pydantic & Rust) is using the LightGBM package maintained by Microsoft. The Fiber endpoint is using the [Leaves](https://pkg.go.dev/github.com/dmitryikh/leaves@v0.0.0-20230708180554-25d19a787328) module which is pure GoLang implementation fo the same library (now unmaintained).\n",
    "\n",
    "The test should show the performance difference between Python and GoLang and their frameworks (e.g. Fiber is using a custom JSON parser which is significnatly more efficient than the standard one in either Python or GoLang). The test is by no means comprehensive and intended as a rough estimation of the difference in latency between both languages, as well as proof of concept for hosting Python trained models in compiled languages, outside of ONNX.\n",
    "\n",
    "Testing was run on an M1 Macbook Pro 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move python path to import src/ modules\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# import modules\n",
    "import time\n",
    "import httpx\n",
    "from numpy import ndarray\n",
    "\n",
    "from src.data.sklearn import generate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate inference dataset\n",
    "X, _ = generate_data(100)\n",
    "\n",
    "# define host & ports\n",
    "HOST_URL = \"http://127.0.0.1\"\n",
    "FIBER = 3000\n",
    "FASTAPI = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define request function\n",
    "def sync_requests(port: int, inference: ndarray) -> None:\n",
    "    \"\"\"send a number of inference requests\"\"\"\n",
    "    with httpx.Client() as client:\n",
    "        for data in inference:\n",
    "            response = client.post(f\"{HOST_URL}:{port}/inference\", json={\"data\": data.tolist()})\n",
    "            if response.status_code != 200:\n",
    "                response.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "The test will draw 50 samples of 100 synchronous requests (of randomly generated data) and average the result to find the mean & median request latency for 100 requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect test data\n",
    "SAMPLES = 50\n",
    "fastapi_samples = []\n",
    "fiber_samples = []\n",
    "\n",
    "for _ in range(SAMPLES):\n",
    "    start = time.perf_counter()\n",
    "    sync_requests(FASTAPI, X)\n",
    "    fastapi_samples.append(time.perf_counter() - start)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    sync_requests(FIBER, X)\n",
    "    fiber_samples.append(time.perf_counter() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean FastAPI latency: 0.261092 seconds\n",
      "Median FastAPI latency: 0.255399 seconds\n",
      "\n",
      "Mean Fiber latency: 0.086377 seconds\n",
      "Median Fiber latency: 0.083931 seconds\n",
      "\n",
      "Fiber vs FastAPI mean difference: 100.56% faster\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "fastapi_mean = statistics.mean(fastapi_samples)\n",
    "fastapi_median = statistics.median(fastapi_samples)\n",
    "print(f\"Mean FastAPI latency: {fastapi_mean:4f} seconds\")\n",
    "print(f\"Median FastAPI latency: {fastapi_median:4f} seconds\\n\")\n",
    "\n",
    "fiber_mean = statistics.mean(fiber_samples)\n",
    "fiber_median = statistics.median(fiber_samples)\n",
    "print(f\"Mean Fiber latency: {fiber_mean:4f} seconds\")\n",
    "print(f\"Median Fiber latency: {fiber_median:4f} seconds\\n\")\n",
    "\n",
    "difference = fastapi_mean - fiber_mean\n",
    "average = statistics.mean([fastapi_mean,fiber_mean])\n",
    "print(f\"Fiber vs FastAPI mean difference: {difference/average:.2%} faster\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelling-RTbxuEjB-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
